!pip install scrapy

#new block

import os
!scrapy startproject test_spider
os.chdir('/content/test_spider/test_spider/spiders')

#new block

%%writefile -a testSpider.py

import scrapy
import time
import random


#scrapy runspider "testSpider.py" -o "cheese.csv"


class testSpider(scrapy.Spider):
    name = "testSpider"
    start_urls = ["https://pro-syr.ru/zakvaski-dlya-syra/mezofilnye/"]

    def parse(self, response):
        links = response.css("div.nameproduct a::attr(href)")
        for link in links:
            time.sleep(random.uniform(1,3))
            yield response.follow(link, self.parse_cheese)

        link = response.css("ul.pagination a::attr(href)").get()
        yield response.follow(link, self.parse)

    def parse_cheese(self, response):
        price = response.css("span.autocalc-product-price::text").get().split(' ')
        if len(price) > 2:
            price_f = int(price[0])*1000 + int(price[1])
        else:
            price_f = price[0]
        yield {
            "name": response.css("div.col-md-9 h1::text").get(),
            "price": int(price_f),
            "availability": response.css("div.product-description b::text").get()
        }

        #response.css("div.col-md-9 h1::text").get() --name
        #response.css("span.autocalc-product-price::text").get() --price
        #response.css("div.product-description b::text").get() --наличие
        
#new block
        
!scrapy runspider 'testSpider.py' -o 'cheese.csv'
